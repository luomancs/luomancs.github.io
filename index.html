<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/favicon.ico">
    <title>Man Luo</title>
    <style type="text/css">
    .center {
        text-align: center;
    }

    .lead {
        font-size: 0.9rem;
        text-align: left;
    }
        
    .subtitle {
        font-size: 1.5rem;
        text-align: left;
        font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;
    }
        
    .title {
        font-size: 1.8rem;
        text-align: left;
        font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;
        font-weight: 450;
    }
    
    .ttitle {
        font-size: 1.2rem;
        text-align: left;
        font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;
    }

    .links {
        text-align: left;
        font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;
    }

    .yyyymm {
        float: left;
        width: 80px;
        /* font-weight: bold; */
        text-align: center;
    }
    </style>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-149582119-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'UA-149582119-2');
    </script>

</head>

<body>
    <div class="container" style="margin-top:10px;">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <!-- Intro -->
                <div>
                    <div class="row">
                        <div class="col-sm-3" align="middle">
                            <img src="images/manluo.jpeg" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:0px;margin-top:10px;margin-bottom:10px">
                        </div>
                        <div class="col" style="margin-top: 15px; margin-bottom: auto; margin-left:5px">
                            <header>
                                <h3 class="title">Man Luo (罗满) </h3>
                                <h3 class="ttitle">Ph.D., Arizona State University</h3>
				                <div class="links">mluo26 [at] asu [dot] edu</h3>
				                <div class="links">
                                    <a href='https://scholar.google.com/citations?hl=en&user=RFeq08UAAAAJ'>Google Scholar</a> / 
				                    <a href='https://github.com/luomancs'>Github</a> / 
                                    <a href='https://www.linkedin.com/in/man-luo-a7aa57178/'>LinkedIn</a> / 
                                    <a href='man_luo_resume.pdf'>CV</a>
                                </div>
                            </header>
                        </div>
                    </div>
                </div>
                <!-- About Me -->
                <hr>
                <div>
                    <h3 class="subtitle">About</h3>
                    <p class="lead">
                        I am a researcher in computer science, specializing in the fields of information retrieval and reading comprehension within natural language processing (NLP) and multimodal domains. My primary research objective is to design advanced models that not only retrieve and harness external knowledge for enhanced comprehension and reasoning but also exhibit generalization to unfamiliar tasks and domains. 

                    </p>
                    <p class="lead">
                        Currently, I am a Research Fellow at Machine Intelligence in Medical Imaging (MI2) lab, Mayo Clinic, AZ, working with Dr. Imon Banerjee and Dr. Bhavik Patel. I was privileged to earn my doctoral degree in 2023 from Arizona State University, Cognition & Intellifent Lab, supervised by Dr. Chitta Baral. I am also lucky to collobrate with amazing industry researchers from Salesforce, Meta and Google during my internship. 
                    </p>
                </div>
                <!-- News -->
                <hr>
                <div>
                    <h3 class="subtitle">News</h3>
                    <div>
                        <h5 style="font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;"> <b>2023</b> </h5>
                        <ul class="lead" style="margin-bottom:7px">
                            <li><span class="yyyymm">[2023.10]:</span> <a href="https://arxiv.org/pdf/2310.00836.pdf">LogiGLUE</a>paper is out</a>: A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models.</li>
                            <li><span class="yyyymm">[2023.07]:</span> A new multimodal-query retriever dataset is public available on github! Check the <a href="https://github.com/luomancs/ReMuQ">dataset</a> and the <a href="https://arxiv.org/abs/2306.00424">paper</a>.</li>
                            <li><span class="yyyymm">[2023.07]:</span> Join Mayo Clinic as a Research Fellow! </li>
                            <li><span class="yyyymm">[2023.05]:</span> Our work on the <a href="https://arxiv.org/pdf/2305.12096.pdf">commonsense assumption of language models </a>is available on arXiv, also check the <a href="https://github.com/nrjvarshney/break_the_common_assumptions">dataset</a>!</li>
                            <li><span class="yyyymm">[2023.05]:</span> My Google internship work on <a href="https://arxiv.org/pdf/2305.14128.pdf">Dr.ICL: Demonstration-Retrieved In-context Learning</a> is available on arXiv, check it out!</li>
                            <li><span class="yyyymm">[2023.05]:</span> Our work on end-to-end multimodal retriever has been accepted to <b>ACL 23!</b></li>
                            <li><span class="yyyymm">[2023.05]:</span> My Meta internship work on hybrid efficient retriever has been accepted to <b>ACL 23</b>, check out <a href="https://arxiv.org/pdf/2210.01371.pdf"> our paper</a>! </li>
                            <li><span class="yyyymm">[2023.04]:</span> Successfully defense my Ph.D. dissertation: <a href="https://www.proquest.com/docview/2813838506?pq-origsite=gscholar&fromopenview=true">Neural Retrieval and Reader for Information Retrieval and Question Answering</a> <a href="https://drive.google.com/file/d/1cZ2qUDtAD8bDB3_Oqp7aVyTAKx4LWXMp/view?usp=sharing">[Slide]</a></li>
                            <li><span class="yyyymm">[2023.01]:</span> Invited talk at <a href = 'https://asu-apg.github.io/serum/'>SERUM @ WACV 2023</a>, <a href='https://drive.google.com/file/d/1B5Q22ew62Sq0-rX6f3In4UL8kbNkK9jq/view?usp=sharing'>[Slide]</a></li>
                        </ul>
                    </div>
                    <div>
                        <h5 style="font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;"> <b>2022</b> </h5>
                        <ul class="lead" style="margin-bottom:7px">
                            <li><span class="yyyymm">[2022.12]:</span><b>2th O-DRUM Workshop</b> will be back at CVPR 2023 with a new rhythm: Open-Domain *Reasoning* under Multimodal settings.</li>
                            <li><span class="yyyymm">[2022.08]:</span> Start internship at <b>Google Research</b>.</li>
                            <li><span class="yyyymm">[2022.08]:</span> Completed <a href="https://arxiv.org/pdf/2205.16005.pdf">thesis proposal</a> and became Ph.D. candidate.</li>
                            <li><span class="yyyymm">[2022.05]:</span> Start internship at <b>Meta Reality Lab </b> working on efficient retrieval task.</li>
                            <li><span class="yyyymm">[2022.05]:</span> 2 papers accpeted to <b>NAACL 2022 SRW </b>.</li>
                            <li><span class="yyyymm">[2022.04]:</span> 1 paper accpeted to <b>NAACL 2022 Finging</b>.</li>
                            <li><span class="yyyymm">[2022.04]:</span> 1 paper accpeted to <b>ACL 2022 Spa-NLP workshop</b>.</li>
                            <li><span class="yyyymm">[2022.02]:</span> 1 paper accpeted to <b>ACL 2022 Finding</b>.</li>
                            <li><span class="yyyymm">[2022.01]:</span> <a href = 'https://asu-apg.github.io/odrum/'>O-Drum</a> Workshop will be held in <b>CVPR 2022</b></li>
                        </ul>
                    </div>
                    <div>
                        <h5 style="font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;"> <b>2021</b> </h5>
                        <ul class="lead" style="margin-bottom:7px">
                            <li><span class="yyyymm">[2021.12]:</span> 1 paper accepted to <b>AAAI 2021</b>. Acceptant rate 15%.</li>
                            <li><span class="yyyymm">[2021.08]:</span> 1 paper accepted to <b>EMNLP 2021</b>.</li>
                            <li><span class="yyyymm">[2021.06]:</span> Yankai Zeng (mentor by me) passed his master thesis and now be a Ph.D. student in <a href='https://www.utdallas.edu/'>UTD</a>.</li>
                            <li><span class="yyyymm">[2021.05]:</span> Research intern at Salesforce and worked with <a href=''>Kazuma Hashimoto</a> and <a href='https://scholar.google.com/citations?user=H_6RQ7oAAAAJ&hl=en'>Yingbo Zhou</a>.</li>
                            <li><span class="yyyymm">[2021.04]:</span> Finalist of 2021 <a href='https://newcollege.asu.edu/asu-graduate-college-recognizes-research-2021-knowledge-mobilization-awards'>Knowledge Mobilization Awards</a>.</li>
                            <li><span class="yyyymm">[2021.03]:</span>Invited talk at exploreCSR workshop (ASU).</li>
                            <li><span class="yyyymm">[2021.02]:</span> 1 paper accepted to <b>EACL 2021</b>.</li>
                        </ul>
                    </div>

                    <div>
                        <h5 style="font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;"> <b>2019</b> </h5>
                        <ul class="lead" style="margin-bottom:7px">
                            <li><span class="yyyymm">[2019.09]:</span> 1 paper accpeted to <b>ICLP 2019</b>.</li>
                            <li><span class="yyyymm">[2019.09]:</span> Presented at <b>ICLP 2019</b> <a href="https://sites.google.com/cs.stonybrook.edu/iclp2019dc/iclp-2019-doctoral-consortium">Doctoral Consortium</a></li>
                            <li><span class="yyyymm">[2019.06]:</span> 1 workshop paper accepted to <b>ASPOCP 2019 </b></li>
                        </ul>
                    </div>

                </div>
                <hr>
                <div>
                    <h3 class="subtitle">Professional Activities and Experience</h3>
                    <div>
                        <h5 style="font-family: Calibri,Candara,Segoe,Segoe UI,Optima,Arial,sans-serif;"> <b>2023</b> </h5>
                        <ul class="lead" style="margin-bottom:7px">
                            <li> Guest Editor of PLOS Digital Medicine </li>
                            <li> Workshop orginzer for O-DRUM <a href="https://asu-apg.github.io/odrum/">2023</a>, <a href="https://asu-apg.github.io/odrum/archive_2022.html">2022</a> </li>
                            <li> Reviewer for AAAI, NIPS, EMNLP, ACL, EACL </li>
                            </ul>
                    </div>
                </div>

                Publications
                <hr>
                <div>
                    <h3 class="subtitle"> Publications</h3>
                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">End-to-end Knowledge Retrieval with Multi-modal Queries </span></br>
                                <span class="font-weight-bold">Man Luo</span>, Zhiyuan Fang, Tejas Gokhale, Yezhou Yang, Chitta Baral</br>
                                ACL 2023</br>
				                <a href='https://arxiv.org/pdf/2306.00424.pdf'>[Paper]</a>
                            </p>
                        </div>
                    </div>

                    <div class="row">

                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">A Study on the Efficiency and Generalization of Light Hybrid Retrievers</span></br>
                                <span class="font-weight-bold">Man Luo</span>, Shashank Jain, Anchit Gupta, Arash Einolghozati, Barlas Oguz Debojeet Chatterjee, Xilun Chen, Chitta Baral, Peyman Heidari</br>
                                ACL 2023</br>
				                <a href='https://arxiv.org/pdf/2210.01371.pdf'>[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">In-BoXBART: Get Instructions into Biomedical Multi-Task Learning</span></br>
                                Mihir Parmar, Swaroop Mishra, Mirali Purohit, <span class="font-weight-bold">Man Luo</span>, M. Hassan Murad, Chitta Baral</br>
                                NAACL 2022 Finding</br>
				                <a href='https://arxiv.org/pdf/2204.07600.pdf'>[Paper]</a>
                                <a href="https://huggingface.co/cogint/in-boxbart">[Model in Huggingface]</a>
                            </p>
                        </div>
                    </div>
                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness</span></br>
                                Tejas Gokhale*, Swaroop Mishra*, <span class="font-weight-bold">Man Luo*</span>, Bhavdeep Singh Sachdeva, Chitta Baral</br>
                                ACL 2022 Finding</br>
				                <a href='https://aclanthology.org/2022.findings-acl.213.pdf'>[Paper]</a>
                            </p>
                        </div>
                    </div>

                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Improving Biomedical Information Retrieval with Neural Retrievers</span></br>
                                <span class="font-weight-bold">Man Luo</span>, Arindam Mitra, Tejas Gokhale, Chitta Baral</br>
                                AAAI 2022 </br>
				                <a href='https://arxiv.org/pdf/2201.07745.pdf'>[Paper]</a>
                            </p>
                        </div>
                    </div>

                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering</span></br>
                                <span class="font-weight-bold">Man Luo*</span>, Yankai Zeng*, Pratyay Banerjee, Chitta Baral</br>
                                EMNLP 2021 </br>
				                <a href='https://arxiv.org/pdf/2109.04014.pdf'>[Paper]</a> <a href='https://github.com/luomancs/retriever_reader_for_okvqa'>[Code]</a>
                            </p>
                        </div>
                    </div>
                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">‘Just because you are right, doesn’t mean I am wrong’: Overcoming a bottleneck in development and evaluation of Open-Ended VQA tasks</span></br>
                                <span class="font-weight-bold">Man Luo</span>, Shailaja Keyur Sampat, Riley Tallman, Yankai Zeng, Manuha Vancha, Akarshan Sajja, Chitta Baral</br>
                                EACL 2021 </br>
				                <a href='https://aclanthology.org/2021.eacl-main.240.pdf'>[Paper]</a> 
                                <a href="https://github.com/luomancs/alternative_answer_set">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Strong equivalence for LPMLN programs</span></br>
                                Joohyung Lee and <span class="font-weight-bold">Man Luo</span></br>
                                ICLP 2019 </br>
				                <a href='https://arxiv.org/pdf/1909.08998.pdf'>[Paper]</a> 
                            </p>
                        </div>
                    </div>
                </div>

                
                <!-- Preprint Papers -->
                <hr>
                <div>
                    <h3 class="subtitle">Preprinted Papers</h3>
                    <!-- OBQA -->
                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">A Simple Approach to Jointly Rank Passages and Select Relevant Sentences in the OBQA Context</span></br>
                                <span class="font-weight-bold">Man Luo</span>, Shuguang Chen, Chitta Baral.</br>
				                arXiv preprint </br>
				                <a href='https://arxiv.org/abs/2109.10497'>[Paper]</a> <a href='https://github.com/luomancs/joint_model'>[Code]</a>
                            </p>
                        </div>
                    </div>

                    <div class="row">
                        
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Can Transformers Reason About Effects of Actions?</span></br>
                                Pratyay Banerjee, Chitta Baral, <span class="font-weight-bold"></span>Man Luo</span>, Arindam Mitra, Kuntal Pal, Tran C Son, Neeraj Varshney
				                arXiv preprint </br>
				                <a href='https://arxiv.org/pdf/2012.09938.pdf'>[Paper]</a>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-2"></div>
            </div>
    <!-- </div> -->
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>

</html>
